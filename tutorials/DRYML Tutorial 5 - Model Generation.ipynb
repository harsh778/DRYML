{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5a1faf-de3c-4e19-8e78-09007e241c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T21:28:49.525087Z",
     "iopub.status.busy": "2023-03-21T21:28:49.524878Z",
     "iopub.status.idle": "2023-03-21T21:28:49.693433Z",
     "shell.execute_reply": "2023-03-21T21:28:49.691657Z",
     "shell.execute_reply.started": "2023-03-21T21:28:49.525033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dryml\n",
    "from dryml import ObjectDef\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2881c1-2d7c-4c74-a030-ffa1e7e22f32",
   "metadata": {},
   "source": [
    "# DRYML Tutorial 5 - Model Generation\n",
    "\n",
    "We have `Object`s, `ObjectDef`s, `Repo`s, `context`, and `Trainable`s. We've also seen some default implemented data transformations in `dryml.data.transforms`, and some metrics in `dryml.metrics`. Not all ML problems require huge models on the scale of GPT-3. Sometimes we have a smallish dataset and smallish models. In these cases it can be useful to check model statistics. For instance, how often does a model achieve a given accuracy? Is the model finicky and sometimes train well and other times terribly? We'll use DRYML's `ObjectDef` factories to define model classes and then generate new copies. We will then train and check the model accuracy and see how much that accuracy varies!\n",
    "\n",
    "## Experiment setup\n",
    "\n",
    "First, we need to set up some utility methods which we will use. `gen_dataset` is a nice function for creating the datasets we need. Then `train_model` and `test_model` are small functions encapsulating the training and testing step which is the same for all `Trainables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a7b9a1-6e69-468e-88f5-a9dede053e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:37.391357Z",
     "start_time": "2022-09-28T15:13:37.383778Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:28:51.448290Z",
     "iopub.status.busy": "2023-03-21T21:28:51.448140Z",
     "iopub.status.idle": "2023-03-21T21:28:51.459634Z",
     "shell.execute_reply": "2023-03-21T21:28:51.457767Z",
     "shell.execute_reply.started": "2023-03-21T21:28:51.448271Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_mod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_mod.py\n",
    "# We use the %%writefile cell magic because dryml compute processes use `spawn` and will need to access the definition of\n",
    "# gen_dataset\n",
    "\n",
    "# Create function to generate the datasets for later use\n",
    "def gen_dataset():\n",
    "    # import some names\n",
    "    import dryml\n",
    "    import tensorflow_datasets as tfds\n",
    "    from dryml.data.tf import TFDataset\n",
    "\n",
    "    # Check that the context has tensorflow ability, but don't get specific.\n",
    "    dryml.context.context_check({'tf': {}})\n",
    "\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'mnist',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True)\n",
    "    \n",
    "    train_ds = TFDataset(\n",
    "        ds_train,\n",
    "        supervised=True,\n",
    "    )\n",
    "    \n",
    "    test_ds = TFDataset(\n",
    "        ds_test,\n",
    "        supervised=True,\n",
    "    )\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8b2180-b2a4-454d-a8ca-faf288ff3ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:37.406198Z",
     "start_time": "2022-09-28T15:13:37.392998Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:28:54.239661Z",
     "iopub.status.busy": "2023-03-21T21:28:54.239512Z",
     "iopub.status.idle": "2023-03-21T21:28:54.246157Z",
     "shell.execute_reply": "2023-03-21T21:28:54.244403Z",
     "shell.execute_reply.started": "2023-03-21T21:28:54.239642Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create function to train a model.\n",
    "# We use ctx_update_objs=True to indicate any objects we give the method should be updated with their\n",
    "# state at the end of the method.\n",
    "@dryml.compute_context(ctx_update_objs=True)\n",
    "def train_model(model):\n",
    "    from temp_mod import gen_dataset\n",
    "    train_ds, _ = gen_dataset()\n",
    "\n",
    "    model.prep_train()\n",
    "    model.train(train_ds)\n",
    "\n",
    "\n",
    "# Create function to test model\n",
    "# Since this method doesn't change the models, we don't have to update them after calling it.\n",
    "@dryml.compute\n",
    "def test_model(model):\n",
    "    from dryml.metrics import categorical_accuracy\n",
    "    from temp_mod import gen_dataset\n",
    "    _, test_ds = gen_dataset()\n",
    "\n",
    "    model.prep_eval()\n",
    "    return categorical_accuracy(model, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe31f1-3dd2-4b25-a758-29ec9a08a836",
   "metadata": {},
   "source": [
    "## Create ML Models\n",
    "\n",
    "Now we'll create a few model classes using `ObjectDef`s. We'll then use `ObjectDef.build` to create instances of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055cfac8-5d57-47e1-9d9e-e5442fb634cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:37.649601Z",
     "start_time": "2022-09-28T15:13:37.408080Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:28:55.485244Z",
     "iopub.status.busy": "2023-03-21T21:28:55.485099Z",
     "iopub.status.idle": "2023-03-21T21:28:55.833921Z",
     "shell.execute_reply": "2023-03-21T21:28:55.832080Z",
     "shell.execute_reply.started": "2023-03-21T21:28:55.485225Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dryml.models\n",
    "import dryml.data\n",
    "import dryml.models.sklearn\n",
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14eeb04a-27f3-4cb7-904c-6f5f6cb89df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:37.654888Z",
     "start_time": "2022-09-28T15:13:37.651633Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:28:57.677455Z",
     "iopub.status.busy": "2023-03-21T21:28:57.677304Z",
     "iopub.status.idle": "2023-03-21T21:28:57.685610Z",
     "shell.execute_reply": "2023-03-21T21:28:57.682617Z",
     "shell.execute_reply.started": "2023-03-21T21:28:57.677435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define some common processing steps so we don't have to build full definitions for them every time.\n",
    "flatten_def = ObjectDef(dryml.data.transforms.Flatten)\n",
    "best_cat_def = ObjectDef(dryml.data.transforms.BestCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98480f8e-e270-453a-9ebe-80ade3d4a1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:37.670551Z",
     "start_time": "2022-09-28T15:13:37.656183Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:28:58.106512Z",
     "iopub.status.busy": "2023-03-21T21:28:58.106364Z",
     "iopub.status.idle": "2023-03-21T21:28:58.116755Z",
     "shell.execute_reply": "2023-03-21T21:28:58.113688Z",
     "shell.execute_reply.started": "2023-03-21T21:28:58.106494Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, we'll build an sklearn model.\n",
    "sklearn_mdl_def = ObjectDef(\n",
    "    dryml.models.Pipe,\n",
    "    flatten_def,\n",
    "    ObjectDef(\n",
    "        dryml.models.sklearn.Trainable,\n",
    "        model=ObjectDef(\n",
    "            dryml.models.sklearn.ClassifierModel,\n",
    "            sklearn.neighbors.KNeighborsClassifier,\n",
    "            n_neighbors=10,\n",
    "        ),\n",
    "        train_fn=ObjectDef(\n",
    "            dryml.models.sklearn.BasicTraining,\n",
    "            num_examples=500,\n",
    "            shuffle=True,\n",
    "            shuffle_buffer_size=5000,\n",
    "        )\n",
    "    ),\n",
    "    best_cat_def,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343dffb4-51f5-446e-906d-e4ea7fbfe5f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:46.291810Z",
     "start_time": "2022-09-28T15:13:37.671802Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:29:02.892866Z",
     "iopub.status.busy": "2023-03-21T21:29:02.892688Z",
     "iopub.status.idle": "2023-03-21T21:29:16.604742Z",
     "shell.execute_reply": "2023-03-21T21:29:16.604270Z",
     "shell.execute_reply.started": "2023-03-21T21:29:02.892846Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:29:07.633084: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8209134615384616"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can generate, train and test a model.\n",
    "simple_tf_reqs = {'tf': {}}\n",
    "temp_model = sklearn_mdl_def.build()\n",
    "train_model(temp_model, call_context_reqs=simple_tf_reqs)\n",
    "test_model(temp_model, call_context_reqs=simple_tf_reqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823f5ff-0c76-43e7-b2e7-0ac557e207b6",
   "metadata": {},
   "source": [
    "## Repeated Model Generation\n",
    "\n",
    "Now, let's write a function which takes a definition, trains some number of models, tests them and returns the trained models as well as the mean accuracy and accuracy deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb21149-cc6b-4d91-a237-14340d4561aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:46.304125Z",
     "start_time": "2022-09-28T15:13:46.295809Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:29:19.869184Z",
     "iopub.status.busy": "2023-03-21T21:29:19.869028Z",
     "iopub.status.idle": "2023-03-21T21:29:19.877913Z",
     "shell.execute_reply": "2023-03-21T21:29:19.874912Z",
     "shell.execute_reply.started": "2023-03-21T21:29:19.869165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_multiple(model_def=None, num_to_train=None, ctx_reqs=None):\n",
    "    models = []\n",
    "    accuracies = []\n",
    "    for i in range(num_to_train):\n",
    "        new_model = model_def.build()\n",
    "        train_model(new_model, call_context_reqs=ctx_reqs)\n",
    "        acc = test_model(new_model, call_context_reqs=ctx_reqs)\n",
    "        accuracies.append(acc)\n",
    "        models.append(new_model)\n",
    "\n",
    "    return models, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d379a9e8-ac5a-4491-a7e9-1d0333908c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:13:46.316625Z",
     "start_time": "2022-09-28T15:13:46.307607Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:29:20.523708Z",
     "iopub.status.busy": "2023-03-21T21:29:20.523561Z",
     "iopub.status.idle": "2023-03-21T21:29:20.531556Z",
     "shell.execute_reply": "2023-03-21T21:29:20.528562Z",
     "shell.execute_reply.started": "2023-03-21T21:29:20.523689Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_to_train = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0338093-a4d8-4452-a2cc-f924c3848626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:14:28.951657Z",
     "start_time": "2022-09-28T15:13:46.323632Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:29:22.237597Z",
     "iopub.status.busy": "2023-03-21T21:29:22.237450Z",
     "iopub.status.idle": "2023-03-21T21:30:27.852707Z",
     "shell.execute_reply": "2023-03-21T21:30:27.852144Z",
     "shell.execute_reply.started": "2023-03-21T21:29:22.237579Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:29:26.460073: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-21 16:29:39.289135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-21 16:29:52.784692: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-21 16:30:05.775738: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-21 16:30:18.903699: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "sklearn_models, sklearn_accuracies = train_multiple(\n",
    "    model_def=sklearn_mdl_def,\n",
    "    num_to_train=num_to_train,\n",
    "    ctx_reqs={'tf': {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12697e7a-6c2e-4ea4-8403-fc76aed08e48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:14:28.959260Z",
     "start_time": "2022-09-28T15:14:28.954798Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:30:51.990605Z",
     "iopub.status.busy": "2023-03-21T21:30:51.990425Z",
     "iopub.status.idle": "2023-03-21T21:30:51.999216Z",
     "shell.execute_reply": "2023-03-21T21:30:51.996235Z",
     "shell.execute_reply.started": "2023-03-21T21:30:51.990586Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn accuracy: 0.8150641025641026+/-0.005604178925329168\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy mean/stddev\n",
    "print(f\"sklearn accuracy: {np.mean(sklearn_accuracies)}+/-{np.std(sklearn_accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b877636-b744-4366-b497-2f73ead806ca",
   "metadata": {},
   "source": [
    "### Training multiple tensorflow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63dc350d-a8b7-4341-96a9-64150e978a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:14:30.285545Z",
     "start_time": "2022-09-28T15:14:28.962032Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:30:54.842768Z",
     "iopub.status.busy": "2023-03-21T21:30:54.842621Z",
     "iopub.status.idle": "2023-03-21T21:30:57.000904Z",
     "shell.execute_reply": "2023-03-21T21:30:57.000347Z",
     "shell.execute_reply.started": "2023-03-21T21:30:54.842749Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import dryml.models.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b09b714-1a01-4c30-9cab-1c0b1d6d2ca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:14:30.292564Z",
     "start_time": "2022-09-28T15:14:30.287411Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:30:57.002138Z",
     "iopub.status.busy": "2023-03-21T21:30:57.001976Z",
     "iopub.status.idle": "2023-03-21T21:30:57.010174Z",
     "shell.execute_reply": "2023-03-21T21:30:57.009626Z",
     "shell.execute_reply.started": "2023-03-21T21:30:57.002116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now the same thing but with tensorflow instead\n",
    "\n",
    "mdl_def = ObjectDef(\n",
    "    dryml.models.tf.keras.SequentialFunctionalModel,\n",
    "    input_shape=(28, 28, 1),\n",
    "    layer_defs=[\n",
    "        ['Conv2D', {'filters': 16, 'kernel_size': 3, 'activation': 'relu'}],\n",
    "        ['Conv2D', {'filters': 16, 'kernel_size': 3, 'activation': 'relu'}],\n",
    "        ['Flatten', {}],\n",
    "        ['Dense', {'units': 10, 'activation': 'linear'}],\n",
    "    ]\n",
    ")\n",
    "tf_mdl_def = ObjectDef(\n",
    "    dryml.models.Pipe,\n",
    "    ObjectDef(\n",
    "        dryml.models.tf.keras.Trainable,\n",
    "        model=mdl_def,\n",
    "        train_fn=ObjectDef(\n",
    "            dryml.models.tf.keras.BasicTraining,\n",
    "            epochs=2\n",
    "        ),\n",
    "        optimizer=ObjectDef(\n",
    "            dryml.models.tf.Wrapper,\n",
    "            tf.keras.optimizers.Adam,\n",
    "        ),\n",
    "        loss=ObjectDef(\n",
    "            dryml.models.tf.Wrapper,\n",
    "            tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "            from_logits=True,\n",
    "        )\n",
    "    ),\n",
    "    ObjectDef(\n",
    "        dryml.data.transforms.BestCat\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9ea6fc-95d5-448f-bd2c-12eb8926dc80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:16:35.555982Z",
     "start_time": "2022-09-28T15:14:30.293847Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:30:58.078023Z",
     "iopub.status.busy": "2023-03-21T21:30:58.077872Z",
     "iopub.status.idle": "2023-03-21T21:33:46.035808Z",
     "shell.execute_reply": "2023-03-21T21:33:46.033890Z",
     "shell.execute_reply.started": "2023-03-21T21:30:58.078003Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:31:01.497771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13870 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:31:10.469867: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.3819 - val_loss: 0.1015\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0777 - val_loss: 0.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:31:26.735944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13867 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n",
      "2023-03-21 16:31:35.243358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13866 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:31:44.088383: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.4399 - val_loss: 0.1258\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0704 - val_loss: 0.1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:32:00.519170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13865 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n",
      "2023-03-21 16:32:09.001445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13864 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:32:17.699206: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.3182 - val_loss: 0.1099\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0741 - val_loss: 0.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:32:33.999434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13865 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n",
      "2023-03-21 16:32:42.845656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13871 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:32:51.570611: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.4297 - val_loss: 0.1287\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0844 - val_loss: 0.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:33:07.194587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13865 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n",
      "2023-03-21 16:33:15.539049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13867 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:33:24.280403: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.2878 - val_loss: 0.1067\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0630 - val_loss: 0.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:33:40.898165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13874 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "tf_models, tf_accuracies = train_multiple(\n",
    "    model_def=tf_mdl_def,\n",
    "    num_to_train=num_to_train,\n",
    "    ctx_reqs={'tf': {'gpu/0': 1.}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33983324-e5bd-4e43-ac12-f5a24f404b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:16:35.565959Z",
     "start_time": "2022-09-28T15:16:35.560017Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:33:46.036849Z",
     "iopub.status.busy": "2023-03-21T21:33:46.036703Z",
     "iopub.status.idle": "2023-03-21T21:33:46.041987Z",
     "shell.execute_reply": "2023-03-21T21:33:46.040263Z",
     "shell.execute_reply.started": "2023-03-21T21:33:46.036830Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf accuracy: 0.9697315705128204+/-0.003142798386126868\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy mean/stddev\n",
    "print(f\"tf accuracy: {np.mean(tf_accuracies)}+/-{np.std(tf_accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702e753-2a88-4ac3-b6c7-55af80fd2ce8",
   "metadata": {},
   "source": [
    "### Training multiple PyTorch models\n",
    "\n",
    "And now, let's have a look at a similar pytorch model, We'll have to add another step to change the order of the indicies of the data since pytorch expects data in nchw format while tensorflow uses nhwc format. We'll also have to add a `TorchDevice` transformation to make sure the data is on the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45004864-966f-411b-9d2d-cf33a646ab79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:16:36.098023Z",
     "start_time": "2022-09-28T15:16:35.568707Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:34:09.402696Z",
     "iopub.status.busy": "2023-03-21T21:34:09.402525Z",
     "iopub.status.idle": "2023-03-21T21:34:09.410981Z",
     "shell.execute_reply": "2023-03-21T21:34:09.407921Z",
     "shell.execute_reply.started": "2023-03-21T21:34:09.402677Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dryml.models.torch\n",
    "import dryml.data.torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27a3313e-8f6f-4b0b-86b2-a2d6ee835647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:16:36.105738Z",
     "start_time": "2022-09-28T15:16:36.099446Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:34:10.198563Z",
     "iopub.status.busy": "2023-03-21T21:34:10.198419Z",
     "iopub.status.idle": "2023-03-21T21:34:10.214492Z",
     "shell.execute_reply": "2023-03-21T21:34:10.211399Z",
     "shell.execute_reply.started": "2023-03-21T21:34:10.198544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdl_def = ObjectDef(\n",
    "    dryml.models.torch.generic.Sequential,\n",
    "    layer_defs=[\n",
    "        [torch.nn.LazyConv2d, (16, 3), {}],\n",
    "        [torch.nn.ReLU, (), {}],\n",
    "        [torch.nn.LazyConv2d, (16, 3), {}],\n",
    "        [torch.nn.ReLU, (), {}],\n",
    "        [torch.nn.Flatten, (), {}],\n",
    "        [torch.nn.LazyLinear, (10,), {}],\n",
    "    ]\n",
    ")\n",
    "torch_mdl_def = ObjectDef(\n",
    "    dryml.models.Pipe,\n",
    "    ObjectDef(\n",
    "        dryml.data.transforms.Transpose,\n",
    "        axes=(2, 0, 1)\n",
    "    ),\n",
    "    ObjectDef(\n",
    "        dryml.data.transforms.Cast,\n",
    "        dtype='float32'\n",
    "    ),\n",
    "    ObjectDef(\n",
    "        dryml.models.torch.generic.Trainable,\n",
    "        model=mdl_def,\n",
    "        train_fn=ObjectDef(\n",
    "            dryml.models.torch.generic.BasicTraining,\n",
    "            optimizer=ObjectDef(\n",
    "                dryml.models.torch.generic.TorchOptimizer,\n",
    "                torch.optim.Adam,\n",
    "                mdl_def,\n",
    "            ),\n",
    "            loss=ObjectDef(\n",
    "                dryml.models.torch.base.Wrapper,\n",
    "                torch.nn.CrossEntropyLoss\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    ObjectDef(\n",
    "        dryml.data.torch.transforms.TorchDevice,\n",
    "        device='cpu'\n",
    "    ),\n",
    "    ObjectDef(\n",
    "        dryml.data.transforms.BestCat\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd5f57cb-b564-4052-b056-523c23bcef13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:19:52.461230Z",
     "start_time": "2022-09-28T15:16:36.107088Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:34:12.220713Z",
     "iopub.status.busy": "2023-03-21T21:34:12.220570Z",
     "iopub.status.idle": "2023-03-21T21:38:06.382367Z",
     "shell.execute_reply": "2023-03-21T21:38:06.381839Z",
     "shell.execute_reply.started": "2023-03-21T21:34:12.220695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "100%|██████████| 1875/1875 [00:20<00:00, 93.68it/s, loss=0.00544] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.0054381017005371785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "100%|██████████| 1875/1875 [00:17<00:00, 105.02it/s, loss=0.00817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.008173266277859026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "100%|██████████| 1875/1875 [00:17<00:00, 109.48it/s, loss=0.00779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.007787893315518158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "100%|██████████| 1875/1875 [00:18<00:00, 102.80it/s, loss=0.00901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.009005006158843268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "100%|██████████| 1875/1875 [00:17<00:00, 104.92it/s, loss=0.00679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.006792048954065831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrafcz2/.conda/envs/opence-v1.6.1-drymldev/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "torch_models, torch_accuracies = train_multiple( model_def=torch_mdl_def,\n",
    "    num_to_train=num_to_train,\n",
    "    # We need to provide 'tf' with some resources because the input datasets are in tensorflow.                                                \n",
    "    ctx_reqs={'tf': {}, 'torch': {'gpu/0': 1.}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a741c26e-9462-44db-acab-2a5b868b3b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T15:19:52.467139Z",
     "start_time": "2022-09-28T15:19:52.463190Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-21T21:40:22.416209Z",
     "iopub.status.busy": "2023-03-21T21:40:22.416029Z",
     "iopub.status.idle": "2023-03-21T21:40:22.423827Z",
     "shell.execute_reply": "2023-03-21T21:40:22.420791Z",
     "shell.execute_reply.started": "2023-03-21T21:40:22.416188Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch accuracy: 0.9693509615384615+/-0.00135716223445149\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy mean/stddev\n",
    "print(f\"torch accuracy: {np.mean(torch_accuracies)}+/-{np.std(torch_accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f5a637-b315-4454-889d-e3cb784b99ea",
   "metadata": {},
   "source": [
    "# Wrap-up\n",
    "\n",
    "We inspected used DRYML's `ObjectDef` to create model templates, then generated models and used `context` to train models in isolated sub-processes preventing GPUs from being locked up by one framework. Once trained, we could compute statistics about these models to learn a little bit more about how well they perform. A model's performance can be due to any of the components that make up the `Trainable` including the training function, and optimizer for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53c5f7-d12b-43a1-a68c-067ac1372ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCE 1.6.1 DRYML Dev [conda env:.conda-opence-v1.6.1-drymldev]",
   "language": "python",
   "name": "conda-env-.conda-opence-v1.6.1-drymldev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
