{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2c0140",
   "metadata": {},
   "source": [
    "# DRYML Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf97ce7",
   "metadata": {},
   "source": [
    "## Ray tune\n",
    "\n",
    "One primary use case for DRYML is hyperparameter tuning of your models. `ObjectDef` provides an easy way to define and construct models. The `train` method of trainables allows uniform training for all models, and DRYML provides a set of interface methods to easily run hyperparameters searches on your models.\n",
    "\n",
    "We'll briefly introduce `ray`, and write a simple hyperparameter tuning example.\n",
    "\n",
    "RAY is a platform for remote process execution. It creates a server which manages connected resources. Jobs can then be sent to those resources in the form of multiple processes confined to specific resources. This is ideal for hyperparameter tuning, and in fact RAY provides the `ray.tune` library for exactly this.\n",
    "\n",
    "This tutorial won't serve as a tutorial for ray, for that please consult the ray documentation available here: https://docs.ray.io/en/latest/index.html and here: https://docs.ray.io/en/latest/tune/index.html\n",
    "\n",
    "Let's start the ray server, and write a simple method for generating models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a17d95f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T22:17:44.924102Z",
     "start_time": "2022-10-04T22:17:44.920605Z"
    }
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90586f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T22:17:51.406717Z",
     "start_time": "2022-10-04T22:17:45.326593Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 17:17:50,820\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.13', ray_version='2.0.0', ray_commit='{{RAY_COMMIT_SHA}}', address_info={'node_ip_address': '192.168.2.31', 'raylet_ip_address': '192.168.2.31', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-04_17-17-45_351374_72258/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-04_17-17-45_351374_72258/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-10-04_17-17-45_351374_72258', 'metrics_export_port': 51160, 'gcs_address': '192.168.2.31:46742', 'address': '192.168.2.31:46742', 'dashboard_agent_listen_port': 52365, 'node_id': 'e01da3893737e7256ccda60784cde5566d3e9db70ac06b9c5a403610'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_gpus=1, num_cpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d916042",
   "metadata": {},
   "source": [
    "## DRYML support\n",
    "\n",
    "DRYML provides support for `ray.tune` in the form of the `dryml.ray.tune.Trainer` class. This class defines a callable function compatible with the ray tune functional API. We just need to supply it with a special callable which can provide a few needed callable methods to setup and run the tune experiment.\n",
    "\n",
    "`dryml.ray.tune.Trainer` expects the arguments:\n",
    "* `name`: The name of the experiment to use\n",
    "* `prep_method`: The callable for creating the necessary callables for setting up the experiment. This must be picklable via `dill`.\n",
    "* `metrics`: A dictionary of metrics to compute after each step of training.\n",
    "\n",
    "Once created, the user can then design their tune experiment in the usual way, and pass the `Trainer` as the callable trainable method.\n",
    "\n",
    "We'll create a `prep_method` which can yield all needed callables for a simple experiment: How large a convolutional kernel is appropriate for a two layer convolutional model for classifying MNIST digits.\n",
    "\n",
    "## Define `prep_method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88d8b994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T14:14:59.385952Z",
     "start_time": "2022-10-05T14:14:59.362362Z"
    }
   },
   "outputs": [],
   "source": [
    "# A callable to create the train/test `Dataset`\n",
    "def data_gen():\n",
    "    import tensorflow_datasets as tfds\n",
    "    from dryml.data.tf import TFDataset\n",
    "    \n",
    "    # Check whether tensorflow support exists\n",
    "    # For the current GPU.\n",
    "    dryml.context.context_check({'tf': {}})\n",
    "    \n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'mnist',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True)\n",
    "    \n",
    "    train_ds = TFDataset(\n",
    "        ds_train,\n",
    "        supervised=True\n",
    "    )\n",
    "    test_ds = TFDataset(\n",
    "        ds_test,\n",
    "        supervised=True\n",
    "    )\n",
    "    return {\n",
    "        'train': train_ds,\n",
    "        'test': test_ds,\n",
    "    }\n",
    "\n",
    "\n",
    "def prep_method():\n",
    "    # A callable to create a repo. This is needed to store completed models for later use.\n",
    "    def repo_gen():\n",
    "        return dryml.Repo(directory='/data0/matthew/Software/NCSA/DRYML/tutorials/models')\n",
    "\n",
    "\n",
    "    # We need another callable since the input datasets have a context\n",
    "    # Requirement, we want the Trainer function to incorporate this\n",
    "    # requirement when building the compute context.\n",
    "    def data_ctx_gen():\n",
    "        return {'tf': {}}\n",
    "\n",
    "    # Model generator method which takes a config, and generates a model\n",
    "    # It also can take a repo keyword argument so already trained components\n",
    "    # Can be grabbed from the repo.\n",
    "    def model_gen(config, repo=None):\n",
    "        import dryml\n",
    "        import dryml.models\n",
    "        import dryml.models.tf\n",
    "        import tensorflow as tf\n",
    "        \n",
    "        # Grab the existing Best Category data transformation\n",
    "        best_cat_def = dryml.ObjectDef(dryml.data.transforms.BestCat)\n",
    "        best_step = repo.get(best_cat_def)\n",
    "        \n",
    "        kernel_size = int(config['kernel_size'])\n",
    "\n",
    "        filters = 32\n",
    "        n_layers = 2\n",
    "        layer_defs = []\n",
    "        for i in range(n_layers):\n",
    "            layer_defs.append(\n",
    "                ['Conv2D', {'filters': filters, 'kernel_size': kernel_size, 'activation': 'relu'}])\n",
    "        layer_defs.append(['Flatten', {}])\n",
    "        layer_defs.append(['Dense', {'units': 10, 'activation': 'linear'}])\n",
    "        \n",
    "        mdl_def = dryml.ObjectDef(\n",
    "            dryml.models.tf.keras.base.SequentialFunctionalModel,\n",
    "            input_shape=(28, 28, 1),\n",
    "            layer_defs=layer_defs,\n",
    "        )\n",
    "        \n",
    "        # Create model definition\n",
    "        mdl_def = dryml.ObjectDef(\n",
    "            dryml.models.Pipe,\n",
    "            dryml.ObjectDef(\n",
    "                dryml.models.tf.keras.Trainable,\n",
    "                # Model definition\n",
    "                model=mdl_def,\n",
    "                # Train method\n",
    "                train_fn=dryml.ObjectDef(\n",
    "                    dryml.models.tf.keras.base.BasicTraining,\n",
    "                    epochs=5,\n",
    "                ),\n",
    "                # Optimizer\n",
    "                optimizer=dryml.ObjectDef(\n",
    "                    dryml.models.tf.ObjectWrapper,\n",
    "                    tf.keras.optimizers.Adam,\n",
    "                ),\n",
    "                # Loss\n",
    "                loss=dryml.ObjectDef(\n",
    "                    dryml.models.tf.ObjectWrapper,\n",
    "                    tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "                    obj_kwargs={\n",
    "                        'from_logits': True\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            best_step,\n",
    "        )\n",
    "        \n",
    "        ctx_reqs = {'tf': {'num_gpus': 1}}\n",
    "\n",
    "        # Return dictionary with the model and optionally, \n",
    "        return {\n",
    "            'model': mdl_def.build(repo=repo),\n",
    "            'ctx_reqs': ctx_reqs,\n",
    "        }\n",
    "\n",
    "    # Return dictionary with defined callables.\n",
    "    return {\n",
    "        'repo': repo_gen,\n",
    "        'data_ctx': data_ctx_gen,\n",
    "        'data': data_gen,\n",
    "        'model': model_gen,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29f81280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T22:28:14.145494Z",
     "start_time": "2022-10-04T22:28:14.128171Z"
    }
   },
   "outputs": [],
   "source": [
    "import dryml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46db9da",
   "metadata": {},
   "source": [
    "Next, let's prepare the `Repo` with needed objects and the `Repo` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a92965a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T22:28:14.155316Z",
     "start_time": "2022-10-04T22:28:14.147747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a repo pointing to the same directory.\n",
    "model_dir = os.path.realpath('./models')\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "repo = dryml.Repo(directory=model_dir)\n",
    "\n",
    "# Create a Best Category trainable, and save it to the repo.\n",
    "best_cat_def = dryml.ObjectDef(dryml.data.transforms.BestCat)\n",
    "# Repo's get method has a special ability when `build_missing_def=True`.\n",
    "# If a non-concrete definition is not in the repo, one instance will be\n",
    "# created and stored in the repo.\n",
    "repo.get(best_cat_def, build_missing_def=True)\n",
    "\n",
    "# Save the objects\n",
    "repo.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e3e5b",
   "metadata": {},
   "source": [
    "Now, let's design the tune experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9dd3fc21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T22:28:14.166754Z",
     "start_time": "2022-10-04T22:28:14.157348Z"
    }
   },
   "outputs": [],
   "source": [
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.air.config import RunConfig, CheckpointConfig\n",
    "from ray.tune.tune_config import TuneConfig\n",
    "import dryml.ray\n",
    "import dryml.metrics\n",
    "import datetime\n",
    "\n",
    "experiment_name = 'TF_ray_test'\n",
    "local_dir = os.path.realpath(f'./ray_results')\n",
    "\n",
    "# Define study space\n",
    "config = {\n",
    "    'kernel_size': ray.tune.randint(3,8),\n",
    "}\n",
    "\n",
    "# Create model trainer\n",
    "model_trainer = dryml.ray.tune.Trainer(\n",
    "    name=experiment_name,\n",
    "    prep_method=prep_method,\n",
    "    metrics={'accuracy': dryml.metrics.scalar.categorical_accuracy},\n",
    ")\n",
    "\n",
    "# Setup Tuner\n",
    "checkpoint_config = CheckpointConfig(\n",
    "    num_to_keep=2,\n",
    "    checkpoint_score_attribute='accuracy',\n",
    "    checkpoint_score_order=\"max\",\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    name=experiment_name,\n",
    "    local_dir=local_dir,\n",
    "    log_to_file=True,\n",
    "    checkpoint_config=checkpoint_config,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# We must set 'reuse_actors=False' so compute contexts can be reset between trials\n",
    "tune_config = TuneConfig(\n",
    "    metric='accuracy',\n",
    "    mode='max',\n",
    "    num_samples=20,\n",
    "    time_budget_s=datetime.timedelta(hours=9),\n",
    "    reuse_actors=False)\n",
    "\n",
    "tuner = ray.tune.Tuner(\n",
    "    ray.tune.with_resources(\n",
    "        model_trainer,\n",
    "        {'cpu': 1, 'gpu': 1},\n",
    "    ),\n",
    "    param_space=config,\n",
    "    tune_config=tune_config,\n",
    "    run_config=run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a777c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T23:09:06.554394Z",
     "start_time": "2022-10-04T22:54:41.798170Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we can start the tune experiment.\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27ad7b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T14:05:27.637665Z",
     "start_time": "2022-10-05T14:05:27.627380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: {'kernel_size': 4}\n",
      "Accuracy: 0.9782652243589743\n",
      "id: ce6ba022-cbad-464c-b308-815d80d9a936\n"
     ]
    }
   ],
   "source": [
    "# Finally, we can inspect the results of this experiment and have a look at the best model!\n",
    "best_result = results.get_best_result(metric='accuracy', mode='max')\n",
    "print(f\"Best configuration: {best_result.config}\")\n",
    "print(f\"Accuracy: {best_result.metrics['accuracy']}\")\n",
    "best_model_id = best_result.metrics['dry_id']\n",
    "print(f\"id: {best_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2faee8ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T14:07:09.146947Z",
     "start_time": "2022-10-05T14:07:08.987242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Refresh the repository\n",
    "repo.load_objects_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3832cfa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T14:07:23.553173Z",
     "start_time": "2022-10-05T14:07:23.495418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fetch the best performing model\n",
    "model = repo.get_obj_by_id(best_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95a577c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T14:20:36.668288Z",
     "start_time": "2022-10-05T14:20:36.659413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets define a method to test the model's accuracy\n",
    "@dryml.compute\n",
    "def test_model(model):\n",
    "    import dryml.metrics\n",
    "    import tensorflow_datasets as tfds\n",
    "    from dryml.data.tf import TFDataset\n",
    "\n",
    "    # Check whether tensorflow support exists\n",
    "    # For the current GPU.\n",
    "    dryml.context.context_check({'tf': {}})\n",
    "\n",
    "    (ds_test,) = tfds.load(\n",
    "        'mnist',\n",
    "        split=['test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True)\n",
    "\n",
    "    test_ds = TFDataset(\n",
    "        ds_test,\n",
    "        supervised=True\n",
    "    )\n",
    "\n",
    "    return dryml.metrics.scalar.categorical_accuracy(model, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5e54e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T14:20:41.591207Z",
     "start_time": "2022-10-05T14:20:37.025047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782652243589743"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And verify recorded accuracy!\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a6ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv_dryml_dev]",
   "language": "python",
   "name": "conda-env-venv_dryml_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
