{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416303b1-c9f4-48f6-ae7d-b483a0687fdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T22:16:57.160350Z",
     "iopub.status.busy": "2023-03-20T22:16:57.160040Z",
     "iopub.status.idle": "2023-03-20T22:16:57.322839Z",
     "shell.execute_reply": "2023-03-20T22:16:57.322037Z",
     "shell.execute_reply.started": "2023-03-20T22:16:57.160323Z"
    }
   },
   "outputs": [],
   "source": [
    "import dryml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd9082-9afd-4340-b13e-2517e14bb7d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T21:48:15.745313Z",
     "iopub.status.busy": "2023-03-20T21:48:15.744677Z",
     "iopub.status.idle": "2023-03-20T21:48:15.752210Z",
     "shell.execute_reply": "2023-03-20T21:48:15.750932Z",
     "shell.execute_reply.started": "2023-03-20T21:48:15.745178Z"
    }
   },
   "source": [
    "# DRYML Tutorial 3 - Compute `Context`s\n",
    "\n",
    "A second major issue ML platforms suffer from is the difficulty of configuring compute resources. By default, most platforms (like TensorFlow) just allocate all memory on a GPU. DRYML attempts to remedy this with a `context` system. The `context` system provides a way to specify a computational resource requirement, and indicate which resources have been claimed. `context` can then check whether the user has authorized the current thread to use the available resources. It can either fail or launch a python sub-process to contain compute operations. This allows device memory to be released when the method completes. Secondly, `Object` supports a 'compute' mode, where the user can contain the allocation of any objects which may require device memory.\n",
    "\n",
    "### DRYML `ResourceRequest`s\n",
    "\n",
    "DRYML implements the `ResourceRequest` to allow the user to inform the library what types of compute resources are required for a given code section or method. Resources can be specified using a dictionary with keywords aligning with the framework you need. We have the following keywords: for tensorflow 'tf', for pytorch 'torch', and for default 'default'. For example, if we want one GPU available for tensorflow use, the resource request would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e832c53-e518-481b-8a20-e975df151dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T15:00:08.310723Z",
     "start_time": "2022-09-23T15:00:08.307445Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-20T22:16:57.735909Z",
     "iopub.status.busy": "2023-03-20T22:16:57.735249Z",
     "iopub.status.idle": "2023-03-20T22:16:57.740508Z",
     "shell.execute_reply": "2023-03-20T22:16:57.739568Z",
     "shell.execute_reply.started": "2023-03-20T22:16:57.735874Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ctx_reqs = {\n",
    "    'default': {'num_gpus': 0},\n",
    "    'tf': {'num_gpus': 1},\n",
    "    'torch': {'num_gpus': 0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db816e-a240-41d4-9f8c-85b877a2c6a8",
   "metadata": {},
   "source": [
    "A resource request is a dictionary with a couple keys to signal a request for specific resources. Right now we can ask for a specific number of cpus/gpus with `num_cpus` and `num_gpus`. We can also ask for specific cpus and gpus with `cpu/<i>` and `gpu/<i>` with a float value between `0.` and `1.`. When possible, if you request a fraction of a gpu, DRYML will configure the corresponding framework for that.\n",
    "\n",
    "Thus, the above context requirements asks for tensorflow with one gpu, and torch with no gpus.\n",
    "\n",
    "With the `ctx_reqs` dictionary, DRYML will create a `ContextManager` which will attempt to create appropriate contexts with the correct resources. If successful, the user will have access to the necessary GPUs, and the correponding libraries will be configured for the requested devices (if possible).\n",
    "\n",
    "> Be aware that most frameworks currently have no way of enforcing limits on memory consumption of GPUs. This means, the user is trusted to try and adhere to the memory requirements which DRYML makes available at all times through the `dryml.get_context()` method which returns the current `ContextManager`.\n",
    "\n",
    "If the user wants their objects to avoid allocating memory on a device, they can simply not set a context, and if a context is required, DRYML will throw an exception.\n",
    "\n",
    "If there is code you suspect may require device memory, DRYML provides the `context_check` method to trigger a check for whether the current context satisfies some resource constraints. Let's check if the current context has two GPUs allocated to tensorflow. (This should fail!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51805b07-fc7e-4f58-b3b6-1bf0969894a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T15:19:32.526770Z",
     "start_time": "2022-09-23T15:19:32.505540Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-20T22:17:00.188582Z",
     "iopub.status.busy": "2023-03-20T22:17:00.188005Z",
     "iopub.status.idle": "2023-03-20T22:17:00.367830Z",
     "shell.execute_reply": "2023-03-20T22:17:00.366418Z",
     "shell.execute_reply.started": "2023-03-20T22:17:00.188528Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NoContextError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoContextError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdryml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/matthew/Software/NCSA/DRYML/src/dryml/context/context_tracker.py:420\u001b[0m, in \u001b[0;36mcontext_check\u001b[0;34m(ctx_reqs)\u001b[0m\n\u001b[1;32m    418\u001b[0m ctx_mgr \u001b[38;5;241m=\u001b[39m context()\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx_mgr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoContextError()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx_mgr\u001b[38;5;241m.\u001b[39msatisfies(ctx_reqs):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContextIncompatibilityError(\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt satisfy requirements \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctx_reqs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNoContextError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dryml.context.context_check({'tf': {'num_gpus': 2}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1293e4e4-22d0-462f-8b51-bcdc8566cb63",
   "metadata": {},
   "source": [
    "## `compute_context` decorator\n",
    "\n",
    "We can create a context in the current process, however currently its not possible to remove the context once created for most frameworks. We can avoid creating a context in our current process, which allows us the possibly change how resources are distributed depending on the model. The `dryml.compute_context` decorator generator is provided by DRYML which gives a wrapped method the power to inspect existing compute contexts, or launch itself in a new process with an appropriate context. This makes it easy to interleave code requiring a context with manager code which may require running a variety of models that could have conflicting context requirements.\n",
    "\n",
    "Now, `dryml.compute_context` is actually a decorator generator meaning, you need to call it to create the decorator you want to use. This allows the user to customize how a given method gets wrapped, and customizes how compute contexts are spawned. DRYML also provides the `dryml.compute` decorator which is just a shortcut to `compute_context()` when generic behavior is fine.\n",
    "\n",
    "`compute_context` has a couple of important arguments which can be specified when the decorator is created (when calling `compute_context`), and can be overridden when actually calling the function.\n",
    "* `ctx_context_reqs`: Probably the most important, specifies a specific set of `context_reqs` to use when checking for an existing context or launching a new context. Override at call time with `call_context_reqs`.\n",
    "* `ctx_use_existing_context` (Default `True`): When `True`, DRYML should try to use an existing context if available. If the existing context doesn't satisfy the given requirements, it will raise a `WrongContextError` exception rather than create a new context. Override at call time with `call_use_existing_context`\n",
    "* `ctx_dont_create_context` (Default `False`): When `False`, DRYML won't try to create a new context ever. if no context exists, it'll throw a `NoContextError` exception, and if the existing context doesn't satisfy the given requirements, it will raise a `WrongContextError` exception. Override at call time with `call_dont_create_context`\n",
    "* `ctx_update_objs` (Default `False`): When `True`, DRYML will update objects in the current process with the state of corresponding objects in the remove process upon completion. Override at call time with `call_update_objs`\n",
    "* `ctx_verbose` (Default `False`): When `True`, DRYML will print some diagnostic information about the whole compute procedure. Override at call time with `call_verbose`.\n",
    "\n",
    "Let's create a test function to which will check if an appropriate context is in place. We can run the method in the current thread where it will fail, but then we will wrap that function in a `compute_context` wrapper to ensure it gets launched with the right context, and see that it succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9623f6-a8f4-404c-9982-08f490708138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T22:29:43.166838Z",
     "iopub.status.busy": "2023-03-20T22:29:43.166282Z",
     "iopub.status.idle": "2023-03-20T22:29:43.173727Z",
     "shell.execute_reply": "2023-03-20T22:29:43.172386Z",
     "shell.execute_reply.started": "2023-03-20T22:29:43.166787Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_ctx():\n",
    "    # A simple method which checks the current context\n",
    "    import dryml\n",
    "    # Check whether any tensorflow context is available\n",
    "    dryml.context.context_check({'tf': {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d799de7-411a-411a-afbb-0f0258dfdadd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T22:29:43.590383Z",
     "iopub.status.busy": "2023-03-20T22:29:43.589179Z",
     "iopub.status.idle": "2023-03-20T22:29:43.622967Z",
     "shell.execute_reply": "2023-03-20T22:29:43.621580Z",
     "shell.execute_reply.started": "2023-03-20T22:29:43.590329Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NoContextError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoContextError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcheck_ctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mcheck_ctx\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdryml\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check whether any tensorflow context is available\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdryml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/matthew/Software/NCSA/DRYML/src/dryml/context/context_tracker.py:420\u001b[0m, in \u001b[0;36mcontext_check\u001b[0;34m(ctx_reqs)\u001b[0m\n\u001b[1;32m    418\u001b[0m ctx_mgr \u001b[38;5;241m=\u001b[39m context()\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx_mgr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoContextError()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx_mgr\u001b[38;5;241m.\u001b[39msatisfies(ctx_reqs):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContextIncompatibilityError(\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt satisfy requirements \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctx_reqs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNoContextError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "check_ctx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28a0f6f2-f4b5-47c4-893f-746f10454409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T22:31:56.198042Z",
     "iopub.status.busy": "2023-03-20T22:31:56.197425Z",
     "iopub.status.idle": "2023-03-20T22:31:56.204755Z",
     "shell.execute_reply": "2023-03-20T22:31:56.203529Z",
     "shell.execute_reply.started": "2023-03-20T22:31:56.197982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrap that method in a compute context with a tensorflow resource request\n",
    "compute_check_ctx = dryml.context.compute_context(ctx_context_reqs=ctx_reqs)(check_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41fc882e-1c43-413d-9538-9064d4921347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T22:31:57.104700Z",
     "iopub.status.busy": "2023-03-20T22:31:57.104114Z",
     "iopub.status.idle": "2023-03-20T22:31:59.731002Z",
     "shell.execute_reply": "2023-03-20T22:31:59.729697Z",
     "shell.execute_reply.started": "2023-03-20T22:31:57.104647Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 17:31:59.258225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "compute_check_ctx()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d13419-3a55-4004-b30b-75531605f870",
   "metadata": {},
   "source": [
    "### Setting a 'current' context\n",
    "\n",
    "If we're sure what kind of context we'll need throughout the program, we can also set the context directly with the `context.set_context` method which takes a resource request. We'll see once we set the current context, the function which failed earlier, will now succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d10f321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T15:13:00.085338Z",
     "start_time": "2022-09-23T15:12:55.410949Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-20T22:32:02.819942Z",
     "iopub.status.busy": "2023-03-20T22:32:02.819128Z",
     "iopub.status.idle": "2023-03-20T22:32:04.783166Z",
     "shell.execute_reply": "2023-03-20T22:32:04.782582Z",
     "shell.execute_reply.started": "2023-03-20T22:32:02.819881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 17:32:04.777831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "dryml.context.set_context(ctx_reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f7597f-d0b5-4762-b26e-d33b68be6d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T22:32:25.025130Z",
     "iopub.status.busy": "2023-03-20T22:32:25.024621Z",
     "iopub.status.idle": "2023-03-20T22:32:25.029762Z",
     "shell.execute_reply": "2023-03-20T22:32:25.028793Z",
     "shell.execute_reply.started": "2023-03-20T22:32:25.025101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now the original function will work\n",
    "check_ctx()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6bccce-c544-460f-af49-03d4652f42a2",
   "metadata": {},
   "source": [
    "We can also do a context check with a set of requirements we know is more than our current context has which will result in an Error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "708995f8-d45a-4786-a00a-eee36dc3e832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T15:19:32.526770Z",
     "start_time": "2022-09-23T15:19:32.505540Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-20T22:32:27.229721Z",
     "iopub.status.busy": "2023-03-20T22:32:27.229396Z",
     "iopub.status.idle": "2023-03-20T22:32:27.267863Z",
     "shell.execute_reply": "2023-03-20T22:32:27.265483Z",
     "shell.execute_reply.started": "2023-03-20T22:32:27.229695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ContextIncompatibilityError",
     "evalue": "Context doesn't satisfy requirements {'tf': {'num_gpus': 2}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mContextIncompatibilityError\u001b[0m               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdryml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/matthew/Software/NCSA/DRYML/src/dryml/context/context_tracker.py:423\u001b[0m, in \u001b[0;36mcontext_check\u001b[0;34m(ctx_reqs)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoContextError()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx_mgr\u001b[38;5;241m.\u001b[39msatisfies(ctx_reqs):\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContextIncompatibilityError(\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt satisfy requirements \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctx_reqs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mContextIncompatibilityError\u001b[0m: Context doesn't satisfy requirements {'tf': {'num_gpus': 2}}"
     ]
    }
   ],
   "source": [
    "dryml.context.context_check({'tf': {'num_gpus': 2}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3d3b2-8b6d-4d04-a4a6-104686c6fc71",
   "metadata": {},
   "source": [
    "And we'll just double check that the current context satisfies the requirements we set out earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae08cd45-0931-455d-af6d-76bf93411fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T15:22:05.721063Z",
     "start_time": "2022-09-23T15:22:05.717136Z"
    },
    "execution": {
     "iopub.execute_input": "2023-03-20T22:32:29.375149Z",
     "iopub.status.busy": "2023-03-20T22:32:29.374338Z",
     "iopub.status.idle": "2023-03-20T22:32:29.381644Z",
     "shell.execute_reply": "2023-03-20T22:32:29.380326Z",
     "shell.execute_reply.started": "2023-03-20T22:32:29.375095Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dryml.context.context_check(ctx_reqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d34ae-b52e-4b1e-83e5-556e36ce88b2",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "\n",
    "Like other components of DRYML, `Dataset`s and `dryml.context` can be used outside of `DRYML`. `dryml.context` is very useful for automatically setting ML framework's device settings. and `Dataset` is great for inspecting and bridging existing datasets between different frameworks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv_dryml_dev]",
   "language": "python",
   "name": "conda-env-venv_dryml_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
