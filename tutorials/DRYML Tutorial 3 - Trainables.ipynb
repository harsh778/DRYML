{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5de0a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T18:40:11.643262Z",
     "start_time": "2022-09-26T18:40:11.638831Z"
    }
   },
   "outputs": [],
   "source": [
    "import dryml\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import dryml.data.tf\n",
    "from dryml.data.tf import TFDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104900e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T21:35:51.638501Z",
     "start_time": "2022-09-23T21:35:51.633534Z"
    }
   },
   "source": [
    "# DRYML Tutorial 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92c0d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T21:35:56.279227Z",
     "start_time": "2022-09-23T21:35:56.275182Z"
    }
   },
   "source": [
    "## DRYML Trainables\n",
    "\n",
    "With `Object`s, `Repo`s, `Dataset`s, and `dryml.context`, we are now ready to do some machine learning!\n",
    "\n",
    "DRYML machine learning model components are all stored within `dryml.models`. Most important of which is `Trainable`. A `Trainable` is the base class which defines DRYML's machine learning API. Any 'trainable' object must inherit from `Trainable`. It also contains `Pipe` which is an analogue to an sklearn pipe. This allows us to chain `Trainable`s together forming a data pipeline.\n",
    "\n",
    "`Trainable` is a subclass of `Object` and that means any `Trainable` can be serialized and loaded later.\n",
    "\n",
    "DRYML provides basic support for major ML frameworks in submodules which you must import.\n",
    "* `dryml.models.tf` - tensorflow\n",
    "* `dryml.models.torch` - pytorch\n",
    "* `dryml.models.sklearn` - sklearn\n",
    "* `dryml.models.xgb` - xgboost\n",
    "\n",
    "Each submodule provides classes which implement basic functionality for serialization, and training. While it is possible to build a monolithic class which implements all of these methods, it is recommended (and the base implementations do this) to use an approach more in line with the Entity Component System (ECS) pattern. In this pattern, `Object`s implement different functionality like training program or model architecture, and are combined in a larger `Object` (the `Trainable`). This larger object can then be customized with different components extending its functionality and reducing the number of classes you need to write.\n",
    "\n",
    "We'll go over some of the sklearn, tensorflow, and pytorch classes as well as the `Trainable` API.\n",
    "\n",
    "First, let's enable all contexts for this notebook. (feel free to allocate a gpu if your machine has one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed73e45f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T18:36:44.742573Z",
     "start_time": "2022-09-26T18:36:44.191374Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 13:36:44.738695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "dryml.context.set_context({'default': {}, 'tf': {'gpu/1': 1.}, 'torch': {}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f4ab0",
   "metadata": {},
   "source": [
    "## Trainable API\n",
    "\n",
    "DRYML `Trainable` objects require the user to implement just four methods.\n",
    "\n",
    "* `prep_train(self)`: This method should perform any necessary preparation for an `Object` to be trained. This is needed in some ML frameworks for example pytorch.\n",
    "* `prep_eval(self)`: This method should perform any necessary prepareation for an `Object` to be evaluated. This is needed in some ML frameworks.\n",
    "* `train(self, data, train_spec=None, train_callbacks=[])`: This method governs the training of the `Trainable`. The api here is meant to be resumable, as well as allow custom callbacks to be called at each step during the training process.\n",
    "* `eval(self, data)`: This method evaluates the model on the data. Typically, the model accepts a `Dataset`, and calls the `apply_X` method with an appropriate lambda function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71769d9",
   "metadata": {},
   "source": [
    "## Traditional ML training with using example\n",
    "\n",
    "Let's train a simple model on the traditional mnist digits dataset. We'll use the `tensorflow_datasets` module to get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472b6738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T18:36:44.849654Z",
     "start_time": "2022-09-26T18:36:44.746142Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load mnist data\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20892a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T18:36:45.349249Z",
     "start_time": "2022-09-26T18:36:45.314250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a simple model with a couple dense layers\n",
    "mdl = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3 , input_shape=(28, 28, 1), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='linear')\n",
    "])\n",
    "# prepare loss and optimizer\n",
    "mdl.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2edaa697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T18:36:50.204387Z",
     "start_time": "2022-09-26T18:36:46.002929Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 13:36:46.765687: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb362903fa0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "mdl.fit(ds_train.batch(32), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c8294ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T18:40:21.328620Z",
     "start_time": "2022-09-26T18:40:20.693435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9695\n"
     ]
    }
   ],
   "source": [
    "# Compute model accuracy\n",
    "total_correct = 0\n",
    "total_num = 0\n",
    "for x, y in ds_test.batch(32):\n",
    "    y_pred = tf.argmax(mdl(x), axis=1).numpy()\n",
    "    total_correct += np.sum(y_pred == y.numpy())\n",
    "    total_num += y_pred.shape[0]\n",
    "\n",
    "print(f\"accuracy: {total_correct/total_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c65361",
   "metadata": {},
   "source": [
    "## Basic tensorflow training with DRYML\n",
    "\n",
    "Now, how do we train such a model in DRYML? Well, we want to create a `Trainable` with the same capability. DRYML offers some pre-built tensorflow functionality. We'll use the generic `Trainable`: `dryml.models.tf.keras.Trainable`. This takes a `model`, an `optimizer`, a `loss`, and a `train_fn`. So, `model` represents a tensorflow model and handles the loading/unloading of the network for compute mode, and save/restore of the object. The `optimizer` object contains a tensorflow optimizer, and `loss` contains a tensorflow loss. Finally, `train_fn` refers to a `dryml.models.tf.TrainFunction` object which defines the training method. The `train_fn` object can store hyperparameters about the training procedure, and `model` can save hyperparameters about the network. This means we can mix and match models and training methods without having to create new classes to contain them. Let's see this in action.\n",
    "\n",
    "We'll use `dryml.models.tf.keras.BasicTraining` which implements a basic training regimine for keras models for `train_fn`, and we'll use `dryml.models.tf.keras.SequentialFunctionalModel` for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff03318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T19:14:39.734809Z",
     "start_time": "2022-09-26T19:14:39.726994Z"
    }
   },
   "outputs": [],
   "source": [
    "import dryml.models.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a920f978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:04:58.563237Z",
     "start_time": "2022-09-26T20:04:58.557145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Object to hold model\n",
    "model = dryml.models.tf.keras.SequentialFunctionalModel(\n",
    "    input_shape=(28, 28, 1),\n",
    "    layer_defs=[\n",
    "        ['Conv2D', {'filters': 16, 'kernel_size': 3, 'activation': 'relu'}],\n",
    "        ['Conv2D', {'filters': 16, 'kernel_size': 3, 'activation': 'relu'}],\n",
    "        ['Flatten', {}],\n",
    "        ['Dense', {'units': 10, 'activation': 'linear'}],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create Object to hold the training algorithm\n",
    "train_fn = dryml.models.tf.keras.BasicTraining(\n",
    "    epochs=1\n",
    ")\n",
    "\n",
    "# Create final trainable\n",
    "mdl = dryml.models.tf.keras.Trainable(\n",
    "    model=model,\n",
    "    optimizer=dryml.models.tf.ObjectWrapper(tf.keras.optimizers.Adam),\n",
    "    loss=dryml.models.tf.ObjectWrapper(tf.keras.losses.SparseCategoricalCrossentropy, obj_kwargs={'from_logits': True}),\n",
    "    train_fn=train_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "548544c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:05:00.735957Z",
     "start_time": "2022-09-26T20:05:00.731467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create TFDatasets to wrap the mnist dataset\n",
    "train_ds = TFDataset(\n",
    "    ds_train,\n",
    "    supervised=True\n",
    ")\n",
    "\n",
    "test_ds = TFDataset(\n",
    "    ds_test,\n",
    "    supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff25bcaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:05:10.609047Z",
     "start_time": "2022-09-26T20:05:00.922477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2927 - val_loss: 0.1156\n"
     ]
    }
   ],
   "source": [
    "# Prepare the model for training\n",
    "mdl.prep_train()\n",
    "# Train the model\n",
    "mdl.train(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "581ae7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:16:06.676682Z",
     "start_time": "2022-09-26T20:16:06.427423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9659455128205128\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy of model, we eval, then use .numpy to transform them into numpy arrays we can compute on like before\n",
    "total_correct = 0\n",
    "total_num = 0\n",
    "for mdl_out, y in mdl.eval(test_ds.batch(batch_size=32)).numpy():\n",
    "    # We have to compute the argmax of the model to get the prediction labels\n",
    "    y_pred = np.argmax(mdl_out, axis=1)\n",
    "    # Now we can compute the accuracy\n",
    "    total_correct += np.sum(y_pred == y)\n",
    "    total_num += y_pred.shape[0]\n",
    "print(f\"Model accuracy: {total_correct/total_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65216436",
   "metadata": {},
   "source": [
    "## `Pipe` and data processing\n",
    "\n",
    "Now, we had to do some extra processing there at the last step. That's where `Pipe` comes in handy. If we need to do some concrete steps to pre or post process the data, we can create more `Trainable`s (which may not need training) to do that processing. Let's create a `Pipe`, and add a `dryml.data.transforms.BestCat` `Trainable` after the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5158bd99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:36:52.037654Z",
     "start_time": "2022-09-26T20:36:52.032376Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = dryml.models.Pipe(\n",
    "    mdl,\n",
    "    dryml.data.transforms.BestCat()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e572e9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:37:19.612574Z",
     "start_time": "2022-09-26T20:37:19.385977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9659455128205128\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy of model, we eval, then use .numpy to transform them into numpy arrays we can compute on like before\n",
    "total_correct = 0\n",
    "total_num = 0\n",
    "for y_pred, y in pipe.eval(test_ds.batch(batch_size=32)).numpy():\n",
    "    # Now we can compute the accuracy\n",
    "    total_correct += np.sum(y_pred == y)\n",
    "    total_num += y_pred.shape[0]\n",
    "print(f\"Model accuracy: {total_correct/total_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18ba78",
   "metadata": {},
   "source": [
    "## DRYML metrics\n",
    "\n",
    "DRYML also provides a few common metrics which can be computed on a `Dataset`. DRYML provides a categorical accuracy metric we can just use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d05242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dryml.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2ddd77d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:41:52.548531Z",
     "start_time": "2022-09-26T20:41:52.269900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9659455128205128"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dryml.metrics.categorical_accuracy(pipe, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45d305",
   "metadata": {},
   "source": [
    "## Sklearn model\n",
    "\n",
    "Now that we've had some experience using DRYML `Trainable`s, Let's look at using an `sklearn` model using the reference implementations in `dryml.models.sklearn`. We'll use `sklearn.neighbors.KNeighborsClassifier` first. One thing to remember about these sklearn methods is that the data needs to have 2 dimensions, so we need to flatten the data before this gets to the model. Thankfully, we have the data transform `dryml.data.transforms.Flatten()`. We'll add that in front of the model in the `Pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbc36645",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T20:52:29.459379Z",
     "start_time": "2022-09-26T20:52:28.030637Z"
    }
   },
   "outputs": [],
   "source": [
    "import dryml.models.sklearn\n",
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e13b8141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T21:04:25.638812Z",
     "start_time": "2022-09-26T21:04:25.633802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build sklearn pipe\n",
    "\n",
    "model_2 = dryml.models.sklearn.ClassifierModel(\n",
    "    sklearn.neighbors.KNeighborsClassifier,\n",
    "    n_neighbors=5,\n",
    ")\n",
    "\n",
    "mdl2 = dryml.models.sklearn.Trainable(\n",
    "    model=model_2,\n",
    "    train_fn=dryml.models.sklearn.BasicTraining(num_examples=1000)\n",
    ")\n",
    "\n",
    "pipe2 = dryml.models.Pipe(\n",
    "    dryml.data.transforms.Flatten(),\n",
    "    mdl2,\n",
    "    dryml.data.transforms.BestCat(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e654f193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T21:04:53.252291Z",
     "start_time": "2022-09-26T21:04:53.184107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the pipe!\n",
    "pipe2.train(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ca959a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T21:05:27.803509Z",
     "start_time": "2022-09-26T21:05:24.568855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8818108974358975"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantly compute model accuracy!\n",
    "dryml.metrics.categorical_accuracy(pipe2, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048febf4",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "\n",
    "This lesson introduced the `Trainable`, the `Pipe` `Trainable`, data transforms like `dryml.data.transforms.Flatten` and `dryml.data.transforms.BestCat`, and metrics like `dryml.metrics.categorical_accuracy`. While users are free to write monolithic `Trainable`s, they are encouraged to write in the ECS style where methods like training function are separated into reusable `Object`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460bb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv_dryml_dev]",
   "language": "python",
   "name": "conda-env-venv_dryml_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
